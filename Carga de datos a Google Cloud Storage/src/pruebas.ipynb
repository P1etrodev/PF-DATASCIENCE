{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import header as h\n",
    "import pandas as pd\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descargar archivos de una url\n",
    "for i in range(5):\n",
    "    URL = h.urls[i]\n",
    "    response = requests.get(URL)\n",
    "    open(\"./Datasets/Descarga/{}.json.gz\".format(h.filenames[i]), \"wb\").write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.gitkeep',\n",
       " 'AmazonInstantVideo.json.gz',\n",
       " 'Automotive.json.gz',\n",
       " 'Baby.json.gz',\n",
       " 'Beauty.json.gz',\n",
       " 'Books.json.gz',\n",
       " 'CDAndVinyl.json.gz',\n",
       " 'CellphonesAndAccessories.json.gz',\n",
       " 'ClothingAndShoesAndJewerly.json.gz',\n",
       " 'DigitalMusic.json.gz',\n",
       " 'Electronics.json.gz',\n",
       " 'GroceryAndGourmetFood.json.gz',\n",
       " 'HealthAndPersonalCare.json.gz',\n",
       " 'HomeAndKitchen.json.gz',\n",
       " 'MoviesAndTV.json.gz',\n",
       " 'MusicalInstruments.json.gz',\n",
       " 'Office.json.gz',\n",
       " 'PatioLawnAndGard.json.gz',\n",
       " 'PetSupplies.json.gz',\n",
       " 'SportsAndOutdoors.json.gz',\n",
       " 'ToolsAndHomeImprovement.json.gz',\n",
       " 'ToysAndGames.json.gz',\n",
       " 'VideoGames.json.gz']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onlyfiles = [f for f in listdir('./Datasets/Descarga/') if isfile(join('./Datasets/Descarga/', f))]\n",
    "onlyfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AmazonInstantVideo.json.gz Chunked!\n",
      "Automotive.json.gz Chunked!\n",
      "Baby.json.gz Chunked!\n",
      "Beauty.json.gz Chunked!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\marco\\OneDrive\\Documentos\\GitHub\\PF-DATASCIENCE\\Carga de datos a Google Cloud Storage\\src\\pruebas.ipynb Celda 4\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/marco/OneDrive/Documentos/GitHub/PF-DATASCIENCE/Carga%20de%20datos%20a%20Google%20Cloud%20Storage/src/pruebas.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(onlyfiles)):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/marco/OneDrive/Documentos/GitHub/PF-DATASCIENCE/Carga%20de%20datos%20a%20Google%20Cloud%20Storage/src/pruebas.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mif\u001b[39;00m(onlyfiles[i]\u001b[39m!=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.gitkeep\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/marco/OneDrive/Documentos/GitHub/PF-DATASCIENCE/Carga%20de%20datos%20a%20Google%20Cloud%20Storage/src/pruebas.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m         h\u001b[39m.\u001b[39;49mgetChunkDF(\u001b[39m'\u001b[39;49m\u001b[39m./Datasets/Descarga/\u001b[39;49m\u001b[39m'\u001b[39;49m,onlyfiles[i],\u001b[39m500000\u001b[39;49m,\u001b[39mtype\u001b[39;49m \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39m.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/marco/OneDrive/Documentos/GitHub/PF-DATASCIENCE/Carga%20de%20datos%20a%20Google%20Cloud%20Storage/src/pruebas.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         \u001b[39mprint\u001b[39m(onlyfiles[i],\u001b[39m'\u001b[39m\u001b[39mChunked!\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\marco\\OneDrive\\Documentos\\GitHub\\PF-DATASCIENCE\\Carga de datos a Google Cloud Storage\\src\\header.py:117\u001b[0m, in \u001b[0;36mgetChunkDF\u001b[1;34m(filepath, filename, chunklen, type)\u001b[0m\n\u001b[0;32m    115\u001b[0m   i \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    116\u001b[0m   \u001b[39mif\u001b[39;00m i \u001b[39m==\u001b[39m chunklen:\n\u001b[1;32m--> 117\u001b[0m     save_partition(filename,df,chunksnum,\u001b[39mtype\u001b[39;49m)\n\u001b[0;32m    118\u001b[0m     df \u001b[39m=\u001b[39m {}; chunksnum \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m; i \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39m# Reinicia variables\u001b[39;00m\n\u001b[0;32m    119\u001b[0m \u001b[39mif\u001b[39;00m i \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m: save_partition(filename,df,chunksnum,\u001b[39mtype\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\marco\\OneDrive\\Documentos\\GitHub\\PF-DATASCIENCE\\Carga de datos a Google Cloud Storage\\src\\header.py:96\u001b[0m, in \u001b[0;36msave_partition\u001b[1;34m(filename, df, chunksnum, type)\u001b[0m\n\u001b[0;32m     94\u001b[0m dfout \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame\u001b[39m.\u001b[39mfrom_dict(df, orient\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     95\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.csv\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m---> 96\u001b[0m     dfout\u001b[39m.\u001b[39;49mto_csv(\u001b[39m'\u001b[39;49m\u001b[39m./Datasets/CSVs/\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m_\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m{}\u001b[39;49;00m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49mformat(filename\u001b[39m.\u001b[39;49mreplace(\u001b[39m'\u001b[39;49m\u001b[39m.json.gz\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m),chunksnum,\u001b[39mtype\u001b[39;49m),quoting\u001b[39m=\u001b[39;49mcsv\u001b[39m.\u001b[39;49mQUOTE_ALL,index\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,encoding\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mUTF-8\u001b[39;49m\u001b[39m'\u001b[39;49m,sep\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m,\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     97\u001b[0m \u001b[39melse\u001b[39;00m: \n\u001b[0;32m     98\u001b[0m     dfout\u001b[39m.\u001b[39mto_json(\u001b[39m'\u001b[39m\u001b[39m./\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(filename\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m.json.gz\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m),chunksnum,\u001b[39m'\u001b[39m\u001b[39m.json\u001b[39m\u001b[39m'\u001b[39m),index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\generic.py:3551\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3540\u001b[0m df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, ABCDataFrame) \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_frame()\n\u001b[0;32m   3542\u001b[0m formatter \u001b[39m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3543\u001b[0m     frame\u001b[39m=\u001b[39mdf,\n\u001b[0;32m   3544\u001b[0m     header\u001b[39m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3548\u001b[0m     decimal\u001b[39m=\u001b[39mdecimal,\n\u001b[0;32m   3549\u001b[0m )\n\u001b[1;32m-> 3551\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[39m.\u001b[39;49mto_csv(\n\u001b[0;32m   3552\u001b[0m     path_or_buf,\n\u001b[0;32m   3553\u001b[0m     line_terminator\u001b[39m=\u001b[39;49mline_terminator,\n\u001b[0;32m   3554\u001b[0m     sep\u001b[39m=\u001b[39;49msep,\n\u001b[0;32m   3555\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[0;32m   3556\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m   3557\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[0;32m   3558\u001b[0m     quoting\u001b[39m=\u001b[39;49mquoting,\n\u001b[0;32m   3559\u001b[0m     columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[0;32m   3560\u001b[0m     index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[0;32m   3561\u001b[0m     mode\u001b[39m=\u001b[39;49mmode,\n\u001b[0;32m   3562\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[0;32m   3563\u001b[0m     quotechar\u001b[39m=\u001b[39;49mquotechar,\n\u001b[0;32m   3564\u001b[0m     date_format\u001b[39m=\u001b[39;49mdate_format,\n\u001b[0;32m   3565\u001b[0m     doublequote\u001b[39m=\u001b[39;49mdoublequote,\n\u001b[0;32m   3566\u001b[0m     escapechar\u001b[39m=\u001b[39;49mescapechar,\n\u001b[0;32m   3567\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m   3568\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\io\\formats\\format.py:1180\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1159\u001b[0m     created_buffer \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1161\u001b[0m csv_formatter \u001b[39m=\u001b[39m CSVFormatter(\n\u001b[0;32m   1162\u001b[0m     path_or_buf\u001b[39m=\u001b[39mpath_or_buf,\n\u001b[0;32m   1163\u001b[0m     line_terminator\u001b[39m=\u001b[39mline_terminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     formatter\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfmt,\n\u001b[0;32m   1179\u001b[0m )\n\u001b[1;32m-> 1180\u001b[0m csv_formatter\u001b[39m.\u001b[39;49msave()\n\u001b[0;32m   1182\u001b[0m \u001b[39mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1183\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\io\\formats\\csvs.py:261\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[0;32m    242\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilepath_or_buffer,\n\u001b[0;32m    243\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    249\u001b[0m \n\u001b[0;32m    250\u001b[0m     \u001b[39m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    251\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwriter \u001b[39m=\u001b[39m csvlib\u001b[39m.\u001b[39mwriter(\n\u001b[0;32m    252\u001b[0m         handles\u001b[39m.\u001b[39mhandle,\n\u001b[0;32m    253\u001b[0m         lineterminator\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mline_terminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    258\u001b[0m         quotechar\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquotechar,\n\u001b[0;32m    259\u001b[0m     )\n\u001b[1;32m--> 261\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_save()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\io\\formats\\csvs.py:266\u001b[0m, in \u001b[0;36mCSVFormatter._save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_need_to_save_header:\n\u001b[0;32m    265\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save_header()\n\u001b[1;32m--> 266\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_save_body()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\io\\formats\\csvs.py:304\u001b[0m, in \u001b[0;36mCSVFormatter._save_body\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[39mif\u001b[39;00m start_i \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m end_i:\n\u001b[0;32m    303\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m--> 304\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_save_chunk(start_i, end_i)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\io\\formats\\csvs.py:315\u001b[0m, in \u001b[0;36mCSVFormatter._save_chunk\u001b[1;34m(self, start_i, end_i)\u001b[0m\n\u001b[0;32m    312\u001b[0m data \u001b[39m=\u001b[39m [res\u001b[39m.\u001b[39miget_values(i) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(res\u001b[39m.\u001b[39mitems))]\n\u001b[0;32m    314\u001b[0m ix \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_index[slicer]\u001b[39m.\u001b[39m_format_native_types(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_number_format)\n\u001b[1;32m--> 315\u001b[0m libwriters\u001b[39m.\u001b[39;49mwrite_csv_rows(\n\u001b[0;32m    316\u001b[0m     data,\n\u001b[0;32m    317\u001b[0m     ix,\n\u001b[0;32m    318\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnlevels,\n\u001b[0;32m    319\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcols,\n\u001b[0;32m    320\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwriter,\n\u001b[0;32m    321\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\_libs\\writers.pyx:72\u001b[0m, in \u001b[0;36mpandas._libs.writers.write_csv_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Cargando archivos descargado en fragmentos csv\n",
    "for i in range(len(onlyfiles)):\n",
    "    if(onlyfiles[i]!='.gitkeep'):\n",
    "        h.getChunkDF('./Datasets/Descarga/',onlyfiles[i],500000,type = '.csv')\n",
    "        print(onlyfiles[i],'Chunked!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onlyfiles = [f for f in listdir('./Datasets/CSVs/') if isfile(join('./Datasets/CSVs/', f))]\n",
    "onlyfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.getChunkDF('./Datasets/Descarga/','AmazonInstantVideo.json.gz',500000,type = '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazamos nulos en cada tabla\n",
    "for i in range(len(onlyfiles)):\n",
    "    if onlyfiles[i] != '.gitkeep':\n",
    "        df = h.ReemplazarNulos('./Datasets/CSVs/',onlyfiles[i])\n",
    "        df.to_csv('./Datasets/ETL/{}'.format(onlyfiles[i]),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onlyfiles = [f for f in listdir('./Datasets/ETL/') if isfile(join('./Datasets/ETL/', f))]\n",
    "onlyfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos columna helpful y creamos una columna Fecha\n",
    "for i in range(len(onlyfiles)):\n",
    "    if onlyfiles[i] != '.gitkeep':\n",
    "        df = h.helpful_Fecha('./Datasets/ETL/',onlyfiles[i])\n",
    "        df.to_csv('./Datasets/ETL/{}'.format(onlyfiles[i]),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargando archivos a GCS\n",
    "# Create a new bucket\n",
    "h.create_bucket('bucket-pf-henry')\n",
    "\n",
    "# Accessing a specific bucket\n",
    "my_bucket = h.storage_client.get_bucket('bucket-pf-henry')\n",
    "\n",
    "# Listando archivos a cargar\n",
    "onlyfiles = [f for f in listdir('./Datasets/ETL/') if isfile(join('./Datasets/ETL/', f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onlyfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(onlyfiles)):\n",
    "    if onlyfiles[i]!='.gitkeep':\n",
    "        h.upload_to_bucket(onlyfiles[i],'./Datasets/ETL/{}'.format(onlyfiles[i]),'bucket-pf-henry')\n",
    "        print(onlyfiles[i],'uploaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Datasets/ETL/MusicalInstruments_1.csv')\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
